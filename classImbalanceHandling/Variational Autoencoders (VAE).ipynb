{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14e3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ykuma\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5463\n",
      "Epoch 2/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.2308\n",
      "Epoch 3/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.1859\n",
      "Epoch 4/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.1947\n",
      "Epoch 5/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.1724\n",
      "Epoch 6/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.1430\n",
      "Epoch 7/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.1312\n",
      "Epoch 8/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1875\n",
      "Epoch 9/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1358\n",
      "Epoch 10/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.1485\n",
      "Epoch 11/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1395\n",
      "Epoch 12/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.1008\n",
      "Epoch 13/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.1009\n",
      "Epoch 14/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.1194\n",
      "Epoch 15/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0976\n",
      "Epoch 16/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.1298\n",
      "Epoch 17/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0793\n",
      "Epoch 18/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.1406\n",
      "Epoch 19/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0938\n",
      "Epoch 20/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1643\n",
      "Epoch 21/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0889\n",
      "Epoch 22/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1414\n",
      "Epoch 23/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0993\n",
      "Epoch 24/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.1326\n",
      "Epoch 25/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.1395\n",
      "Epoch 26/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0977\n",
      "Epoch 27/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0952\n",
      "Epoch 28/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0973\n",
      "Epoch 29/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0956\n",
      "Epoch 30/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0729\n",
      "Epoch 31/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0955\n",
      "Epoch 32/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.1013\n",
      "Epoch 33/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0909\n",
      "Epoch 34/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0866\n",
      "Epoch 35/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0776\n",
      "Epoch 36/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0810\n",
      "Epoch 37/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0719\n",
      "Epoch 38/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0959\n",
      "Epoch 39/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0805\n",
      "Epoch 40/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0977\n",
      "Epoch 41/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0815\n",
      "Epoch 42/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0699\n",
      "Epoch 43/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0696\n",
      "Epoch 44/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0795\n",
      "Epoch 45/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0756\n",
      "Epoch 46/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0710\n",
      "Epoch 47/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0673\n",
      "Epoch 48/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0782\n",
      "Epoch 49/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0720\n",
      "Epoch 50/50\n",
      "\u001b[1m3341/3341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0679\n",
      "\u001b[1m13364/13364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    134292\n",
      "           1       0.92      0.78      0.85       896\n",
      "           2       1.00      1.00      1.00     22133\n",
      "           3       0.88      0.85      0.86     13729\n",
      "\n",
      "    accuracy                           0.98    171050\n",
      "   macro avg       0.95      0.91      0.92    171050\n",
      "weighted avg       0.98      0.98      0.98    171050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "X = df.drop(columns=[\"Unnamed: 0\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define sampling function using TensorFlow ops\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# VAE architecture\n",
    "input_dim = X_scaled.shape[1]\n",
    "inputs = Input(shape=(input_dim,))\n",
    "h = Dense(64, activation='relu')(inputs)\n",
    "z_mean = Dense(2)(h)\n",
    "z_log_var = Dense(2)(h)\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "decoder_h = Dense(64, activation='relu')(z)\n",
    "outputs = Dense(input_dim)(decoder_h)\n",
    "\n",
    "vae = Model(inputs, outputs)\n",
    "vae.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train VAE\n",
    "vae.fit(X_scaled, X_scaled, epochs=50, batch_size=128)\n",
    "\n",
    "# Generate synthetic data\n",
    "X_synthetic = vae.predict(X_scaled)\n",
    "\n",
    "# Combine real and synthetic data\n",
    "X_balanced = np.concatenate([X_scaled, X_synthetic])\n",
    "y_balanced = np.concatenate([y, y])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
