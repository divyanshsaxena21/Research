{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# borderline-SMOTE SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest Classifier\n",
    "2. Bagging Classifier\n",
    "3. XGBoost\n",
    "4. Gradient Boosting \n",
    "5. Extra Trees\n",
    "6. Gaussian Naïve Bayes\n",
    "7. CART\n",
    "8. KNN\n",
    "9. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVMSMOTE... this may take a long time\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # <-- Import MinMaxScaler\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reading the file\n",
    "df = pd.read_csv(\"all_three.csv\")\n",
    "\n",
    "# Dropping the first column because it is of no use  \n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "# Segregating the features and labels \n",
    "Y = df[['label']]\n",
    "X = df[['rec/sent','amount','size','weight','version','lock_time','is_coinbase',\n",
    "        'has_witness','input_count','output_count','input_total_usd','output_total_usd',\n",
    "        'fee_usd','fee_per_kb_usd','fee_per_kwu_usd','cdd_total']]\n",
    "\n",
    "# Apply Min-Max scaling instead of decimal point normalization\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Splitting the data (60-40 split)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=42, stratify=Y\n",
    ") \n",
    "\n",
    "# File to save resampled dataset\n",
    "resampled_file = \"x_y_train_resampled_SVMSMOTE.csv\"\n",
    "\n",
    "if not os.path.exists(resampled_file):\n",
    "    print(\"Running SVMSMOTE... this may take a long time\")\n",
    "    Borderline_SMOTE_SVM = SVMSMOTE()\n",
    "    x_res, y_res = Borderline_SMOTE_SVM.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Merge x and y to save in one CSV\n",
    "    resampled_df = pd.concat([pd.DataFrame(x_res, columns=x_train.columns), \n",
    "                              pd.DataFrame(y_res, columns=[\"label\"])], axis=1)\n",
    "    resampled_df.to_csv(resampled_file, index=False)\n",
    "    print(f\"Resampled dataset saved to {resampled_file}\")\n",
    "else:\n",
    "    print(\"Loading resampled dataset from CSV...\")\n",
    "    resampled_df = pd.read_csv(resampled_file)\n",
    "    x_res = resampled_df.drop(columns=[\"label\"])\n",
    "    y_res = resampled_df[[\"label\"]]\n",
    "\n",
    "# Now x_res, y_res are your oversampled training sets\n",
    "x_train, y_train = x_res, y_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Required imports\n",
    "# -----------------------------\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as mplplt  # renamed to avoid overwriting issues\n",
    "import psutil, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# -----------------------------\n",
    "# Full check_prediction function\n",
    "# -----------------------------\n",
    "def check_prediction(y_true, y_pred, start_time, model=None, x_test=None, x_train=None): \n",
    "    runtime_sec = time() - start_time\n",
    "    \n",
    "    # RAM usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    ram_used_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    \n",
    "    # Base metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # ROC AUC\n",
    "    roc_auc = None\n",
    "    y_probs = None\n",
    "    try:\n",
    "        if model is not None and x_test is not None:\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_probs = model.predict_proba(x_test)\n",
    "            elif hasattr(model, \"decision_function\"):\n",
    "                y_probs = model.decision_function(x_test)\n",
    "\n",
    "        if y_probs is not None:\n",
    "            classes = np.unique(y_true)\n",
    "            y_true_bin = label_binarize(y_true, classes=classes)\n",
    "            roc_auc = roc_auc_score(y_true_bin, y_probs, average=\"weighted\", multi_class=\"ovr\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ ROC AUC not available: {e}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\n===== Evaluation Results =====\")\n",
    "    print(f\"runtime_sec: {runtime_sec:.4f}\")\n",
    "    print(f\"ram_used_mb: {ram_used_mb:.4f}\")\n",
    "    print(f\"accuracy: {acc:.4f}\")\n",
    "    print(f\"precision: {prec:.4f}\")\n",
    "    print(f\"recall: {rec:.4f}\")\n",
    "    print(f\"roc_auc: {roc_auc:.4f}\" if roc_auc else \"roc_auc: N/A\")\n",
    "    print(\"confusion_matrix:\\n\", cm)\n",
    "    print(\"================================\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Confusion Matrix Heatmap\n",
    "    # -----------------------------\n",
    "    fig_cm, ax_cm = mplplt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax_cm)\n",
    "    ax_cm.set_title(\"Confusion Matrix\")\n",
    "    ax_cm.set_xlabel(\"Predicted\")\n",
    "    ax_cm.set_ylabel(\"True\")\n",
    "    mplplt.show()\n",
    "\n",
    "    # -----------------------------\n",
    "    # ROC Curve plotting\n",
    "    # -----------------------------\n",
    "    if y_probs is not None:\n",
    "        try:\n",
    "            if y_probs.ndim > 1 and y_probs.shape[1] > 1:  # multiclass\n",
    "                n_classes = y_probs.shape[1]\n",
    "                classes = np.unique(y_true)\n",
    "                y_true_bin = label_binarize(y_true, classes=classes)\n",
    "\n",
    "                fig_roc, ax_roc = mplplt.subplots(figsize=(7,6))\n",
    "                for i in range(n_classes):\n",
    "                    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "                    roc_auc_val = auc(fpr, tpr)\n",
    "                    ax_roc.plot(fpr, tpr, label=f\"Class {classes[i]} (AUC={roc_auc_val:.2f})\")\n",
    "\n",
    "                ax_roc.plot([0,1],[0,1],'k--')\n",
    "                ax_roc.set_title(\"ROC Curves (Multiclass)\")\n",
    "                ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "                ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "                ax_roc.legend(loc=\"lower right\")\n",
    "                mplplt.show()\n",
    "            else:  # binary\n",
    "                if len(np.unique(y_true)) == 2:\n",
    "                    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "                    roc_auc_val = auc(fpr, tpr)\n",
    "                    fig_roc, ax_roc = mplplt.subplots(figsize=(7,6))\n",
    "                    ax_roc.plot(fpr, tpr, label=f\"AUC={roc_auc_val:.2f}\")\n",
    "                    ax_roc.plot([0,1],[0,1],'k--')\n",
    "                    ax_roc.set_title(\"ROC Curve (Binary)\")\n",
    "                    ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "                    ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "                    ax_roc.legend(loc=\"lower right\")\n",
    "                    mplplt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ ROC plotting failed: {e}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Feature Correlation Heatmap\n",
    "    # -----------------------------\n",
    "    if x_train is not None:\n",
    "        corr = pd.DataFrame(x_train).corr()\n",
    "        fig_corr, ax_corr = mplplt.subplots(figsize=(10, 8))\n",
    "        sns.heatmap(corr, cmap=\"coolwarm\", annot=False, ax=ax_corr)\n",
    "        ax_corr.set_title(\"Feature Correlation Heatmap\")\n",
    "        mplplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()\n",
    "print(\"training data size\")\n",
    "print(y_train.value_counts())\n",
    "print(\"testing data size\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf2=pd.DataFrame({'label':df['label'].value_counts().to_list()},\n",
    "                    index=['Exchanges','Gambling', 'Mixing','Services'])\n",
    "\n",
    "plt=pf2.plot.pie(y='label',autopct='%1.1f%%',figsize=(5,5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model = RandomForestClassifier()  \n",
    "model.fit(x_train, y_train) \n",
    "\n",
    "# predicting the model in testing dataset\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluating the model \n",
    "check_prediction(y_test, y_pred, start_time, model, x_test, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "def notify_done():\n",
    "    system = platform.system()\n",
    "    if system == \"Windows\":\n",
    "        import winsound\n",
    "        winsound.Beep(1000, 700)   # frequency=1000 Hz, duration=700ms\n",
    "    elif system == \"Darwin\":  # macOS\n",
    "        os.system('say \"Task completed\"')\n",
    "    else:  # Linux\n",
    "        os.system('echo -e \"\\a\"')  # terminal beep\n",
    "\n",
    "# --- your code ---\n",
    "print(\"Starting long process...\")\n",
    "\n",
    "# Place all your ML code here\n",
    "# ...\n",
    "\n",
    "print(\"Process completed!\")\n",
    "notify_done()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize the base classifier\n",
    "base_model = DecisionTreeClassifier()\n",
    "\n",
    "# Number of base classifiers\n",
    "n_trees = 50\n",
    "\n",
    "# Initialize BaggingClassifier (use 'estimator' instead of 'base_estimator')\n",
    "model = BaggingClassifier(\n",
    "    estimator=base_model,  # updated argument name\n",
    "    n_estimators=n_trees,\n",
    "    random_state=50\n",
    ")\n",
    "\n",
    "# Optional: Cross-validation score\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=50)\n",
    "res = cross_val_score(model, X, Y.values.ravel(), cv=kfold)\n",
    "print(f\"Cross-validation scores: {res}\")\n",
    "print(f\"Mean CV score: {res.mean():.4f}\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=model,        # needed for ROC AUC\n",
    "    x_test=x_test,      # needed for predict_proba\n",
    "    x_train=x_train     # optional: for feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize the classifier\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # avoid warning\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Predict the test dataset\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=model,        # needed for ROC AUC\n",
    "    x_test=x_test,      # needed for predict_proba\n",
    "    x_train=x_train     # optional: for feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(x_train, y_train.values.ravel())  # flatten to 1D if needed\n",
    "\n",
    "# Predict test dataset\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=model,        # needed for ROC AUC\n",
    "    x_test=x_test,      # needed for predict_proba\n",
    "    x_train=x_train     # optional: feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train.values.ravel())  # flatten to 1D\n",
    "\n",
    "# Predict test dataset\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Evaluate with check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=clf,        # needed for ROC AUC\n",
    "    x_test=x_test,    # needed for predict_proba\n",
    "    x_train=x_train   # optional: feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize Gaussian Naive Bayes\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train.values.ravel())  # flatten to 1D\n",
    "\n",
    "# Predict test dataset\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=model,        # needed for ROC AUC\n",
    "    x_test=x_test,      # needed for predict_proba\n",
    "    x_train=x_train     # optional: feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees (CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Create Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(x_train, y_train.values.ravel())  # flatten to 1D\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=clf,        # needed for ROC AUC\n",
    "    x_test=x_test,    # needed for predict_proba\n",
    "    x_train=x_train   # optional: feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(x_train, y_train.values.ravel())  # flatten to 1D\n",
    "\n",
    "# Predict the test dataset\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=knn,        # needed for ROC AUC\n",
    "    x_test=x_test,    # needed for predict_proba\n",
    "    x_train=x_train   # optional: feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Start timer\n",
    "current_time = time()\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "adboost = AdaBoostClassifier()\n",
    "adboost.fit(x_train, y_train.values.ravel())  # flatten to 1D\n",
    "\n",
    "# Predict the test dataset\n",
    "y_pred = adboost.predict(x_test)\n",
    "\n",
    "# Evaluate using check_prediction\n",
    "check_prediction(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    start_time=current_time,\n",
    "    model=adboost,    # needed for ROC AUC\n",
    "    x_test=x_test,    # needed for predict_proba\n",
    "    x_train=x_train   # optional: feature correlation heatmap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "def notify_done():\n",
    "    system = platform.system()\n",
    "    if system == \"Windows\":\n",
    "        import winsound\n",
    "        winsound.Beep(1000, 700)   # frequency=1000 Hz, duration=700ms\n",
    "    elif system == \"Darwin\":  # macOS\n",
    "        os.system('say \"Task completed\"')\n",
    "    else:  # Linux\n",
    "        os.system('echo -e \"\\a\"')  # terminal beep\n",
    "\n",
    "# --- your code ---\n",
    "print(\"Starting long process...\")\n",
    "\n",
    "# Place all your ML code here\n",
    "# ...\n",
    "\n",
    "print(\"Process completed!\")\n",
    "notify_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
